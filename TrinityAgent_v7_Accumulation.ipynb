{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdaca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DEFAULT_CONFIG = {\n",
    "    # Assets\n",
    "    \"TICKERS\": [\"SPY\", \"IWM\", \"^VIX\", \"SHY\"], \n",
    "    \"TARGET_ASSET\": \"SPY\",\n",
    "    \n",
    "    # Dates\n",
    "    \"TRAIN_START\": \"2015-01-01\",\n",
    "    \"TRAIN_END\": \"2023-12-31\",\n",
    "    \"TEST_START\": \"2024-01-02\",\n",
    "    \"TEST_END\": \"2025-05-05\",\n",
    "    \n",
    "    # Crisis Training Periods\n",
    "    \"CRISIS_PERIODS\": [\n",
    "        (\"2018-10-01\", \"2019-01-01\"), # Volmageddon\n",
    "        (\"2020-01-01\", \"2020-05-01\"), # COVID\n",
    "        (\"2022-01-01\", \"2022-12-31\"), # Bear\n",
    "    ],\n",
    "    \n",
    "    # Hyperparameters\n",
    "    \"WINDOW_SIZE\": 60, \n",
    "    \"ADX_THRESHOLD\": 25,\n",
    "    \"TARGET_VOL\": 0.40,\n",
    "    \n",
    "    # Fixed Params\n",
    "    \"BB_STD\": 2.0,\n",
    "    \"LEARNING_RATE\": 3e-4,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"TRAINING_STEPS\": 50000, \n",
    "    \"INITIAL_BALANCE\": 100000,\n",
    "    \"FEES\": 0.0005,\n",
    "    \"BORROW_RATE\": 0.0002, \n",
    "    \"ACTION_SCALER\": 5.0,\n",
    "    \"MAX_LEVERAGE\": 1.0, \n",
    "    \"USE_VOL_TARGETING\": True,\n",
    "    \"SMA_TREND_FILTER\": True,\n",
    "    \"LONG_ONLY\": False \n",
    "}\n",
    "\n",
    "# --- DATA PROCESSOR (UPDATED WITH JUMP DETECTOR) ---\n",
    "class DataProcessor:\n",
    "    def __init__(self, tickers, config):\n",
    "        self.tickers = list(set(tickers))\n",
    "        self.config = config\n",
    "        \n",
    "    def download(self, start, end):\n",
    "        try:\n",
    "            if self.config['TARGET_ASSET'] not in self.tickers:\n",
    "                self.tickers.append(self.config['TARGET_ASSET'])\n",
    "                \n",
    "            print(f\"Fetching data for: {self.tickers} ({start} to {end})\")\n",
    "            data = yf.download(self.tickers, start=start, end=end, progress=False)\n",
    "            \n",
    "            if isinstance(data.columns, pd.MultiIndex):\n",
    "                if 'Close' in data.columns.levels[0]: data = data.xs('Close', level=0, axis=1)\n",
    "                elif 'Adj Close' in data.columns.levels[0]: data = data.xs('Adj Close', level=0, axis=1)\n",
    "                elif 'Close' in data.columns.levels[1]: data = data.xs('Close', level=1, axis=1)\n",
    "            \n",
    "            if isinstance(data, pd.Series): \n",
    "                data = data.to_frame()\n",
    "                if self.config['TARGET_ASSET'] not in data.columns:\n",
    "                    data.columns = [self.config['TARGET_ASSET']]\n",
    "            \n",
    "            ohlc = yf.download(self.config['TARGET_ASSET'], start=start, end=end, progress=False)\n",
    "            return data, ohlc\n",
    "        except Exception as e:\n",
    "            print(f\"Data Download Error: {e}\")\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    def calculate_lee_mykland(self, df, window=20):\n",
    "        \"\"\"\n",
    "        Calculates the Lee-Mykland Statistic for Jump Detection.\n",
    "        Adapted for Daily Data (using smaller window than hourly).\n",
    "        \"\"\"\n",
    "        # 1. Log Returns\n",
    "        log_ret = np.log(df / df.shift(1))\n",
    "        \n",
    "        # 2. Bipower Variation (Local Volatility Estimate)\n",
    "        # BV = (pi/2) * rolling_mean( |r_t| * |r_{t-1}| )\n",
    "        abs_ret = np.abs(log_ret)\n",
    "        bv_terms = abs_ret * abs_ret.shift(1)\n",
    "        local_vol = np.sqrt((np.pi / 2) * bv_terms.rolling(window=window).mean())\n",
    "        \n",
    "        # 3. L-Statistic\n",
    "        # Avoid division by zero with small epsilon\n",
    "        l_stat = log_ret / (local_vol + 1e-9)\n",
    "        \n",
    "        return l_stat.fillna(0)\n",
    "\n",
    "    def add_features(self, df, ohlc):\n",
    "        target = self.config['TARGET_ASSET']\n",
    "        if df.empty or target not in df.columns: return pd.DataFrame()\n",
    "        \n",
    "        df = df.copy()\n",
    "        \n",
    "        # 1. Base Returns\n",
    "        df['returns'] = df[target].pct_change()\n",
    "        \n",
    "        # --- NEW: JUMP DETECTION FEATURES ---\n",
    "        # We add the L-Statistic to the features so agents can learn from it\n",
    "        l_stat = self.calculate_lee_mykland(df[target], window=20)\n",
    "        df['l_stat'] = l_stat\n",
    "        # ------------------------------------\n",
    "        \n",
    "        # 2. Trend (ADX & Directional Indicators)\n",
    "        high = ohlc['High']\n",
    "        low = ohlc['Low']\n",
    "        close = ohlc['Close']\n",
    "        \n",
    "        df['tr'] = np.maximum(high - low, \n",
    "                   np.maximum(abs(high - close.shift(1)), \n",
    "                              abs(low - close.shift(1))))\n",
    "        \n",
    "        df['dm_plus'] = np.where((high - high.shift(1)) > (low.shift(1) - low), \n",
    "                                 np.maximum(high - high.shift(1), 0), 0)\n",
    "        df['dm_minus'] = np.where((low.shift(1) - low) > (high - high.shift(1)), \n",
    "                                  np.maximum(low.shift(1) - low, 0), 0)\n",
    "        \n",
    "        window = 14\n",
    "        df['tr_s'] = df['tr'].rolling(window).mean()\n",
    "        df['dp_s'] = df['dm_plus'].rolling(window).mean()\n",
    "        df['dm_s'] = df['dm_minus'].rolling(window).mean()\n",
    "        \n",
    "        df['di_plus'] = 100 * (df['dp_s'] / df['tr_s'])\n",
    "        df['di_minus'] = 100 * (df['dm_s'] / df['tr_s'])\n",
    "        df['dx'] = 100 * abs(df['di_plus'] - df['di_minus']) / (df['di_plus'] + df['di_minus'])\n",
    "        df['adx'] = df['dx'].rolling(window).mean()\n",
    "        \n",
    "        # 3. Mean Reversion\n",
    "        sma = df[target].rolling(20).mean()\n",
    "        std = df[target].rolling(20).std()\n",
    "        df['bb_width'] = (std * 2 * 2) / sma\n",
    "        df['pct_b'] = (df[target] - (sma - 2*std)) / (4*std)\n",
    "        \n",
    "        # 4. Crisis / Macro\n",
    "        if '^VIX' in df.columns:\n",
    "            df['vix_norm'] = (df['^VIX'] - 15) / 40\n",
    "        else:\n",
    "            df['vix_norm'] = 0\n",
    "            \n",
    "        sma200 = df[target].rolling(200).mean()\n",
    "        df['dist_sma200'] = (df[target] - sma200) / sma200\n",
    "        \n",
    "        # 5. Volatility\n",
    "        df['realized_vol_20d'] = df['returns'].rolling(20).std() * np.sqrt(252)\n",
    "        df['vol_percentile'] = df['realized_vol_20d'].rolling(252).rank(pct=True)\n",
    "        \n",
    "        return df.fillna(0)\n",
    "\n",
    "    def get_data(self, start, end):\n",
    "        df, ohlc = self.download(start, end)\n",
    "        return self.add_features(df, ohlc)\n",
    "\n",
    "    def get_crisis_data(self):\n",
    "        dfs = []\n",
    "        for s, e in self.config['CRISIS_PERIODS']:\n",
    "            d, o = self.download(s, e)\n",
    "            dfs.append(self.add_features(d, o))\n",
    "        return pd.concat(dfs).reset_index(drop=True).fillna(0)\n",
    "\n",
    "# --- ENVIRONMENT (UPDATED OBSERVATION SPACE) ---\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, df, config, mode='trend'):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.mode = mode \n",
    "        self.n_features = df.shape[1]\n",
    "        self.window = config['WINDOW_SIZE']\n",
    "        self.current_step = self.window\n",
    "        \n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.window * self.n_features,), dtype=np.float32)\n",
    "        \n",
    "        self.data = df.values.astype(np.float32)\n",
    "        self.cols = df.columns.tolist()\n",
    "        self.idx_sma = self.cols.index('dist_sma200') if 'dist_sma200' in self.cols else -1\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.current_step = self.window\n",
    "        return self._get_obs(), {}\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        return self.data[self.current_step-self.window : self.current_step].flatten()\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.current_step >= len(self.df) - 1:\n",
    "            return self._get_obs(), 0, True, False, {}\n",
    "            \n",
    "        act = np.clip(action[0], -1, 1)\n",
    "        ret = self.data[self.current_step, 0] \n",
    "        \n",
    "        reward = 0\n",
    "        if self.mode == 'trend':\n",
    "            reward = act * ret * 100\n",
    "            if self.idx_sma != -1:\n",
    "                sma_dist = self.data[self.current_step, self.idx_sma]\n",
    "                if sma_dist > 0 and act > 0.1: reward += 0.05 * act \n",
    "                elif sma_dist < 0 and act < -0.1: reward += 0.05 * abs(act)\n",
    "                \n",
    "        elif self.mode == 'mean_rev':\n",
    "            reward = (act * ret * 100) - (0.05 * abs(act))\n",
    "            \n",
    "        elif self.mode == 'crisis':\n",
    "            # Logic: Reward Shorting or Safety during Crash\n",
    "            reward = (act * ret * 100)\n",
    "            if ret < -0.01 and act < -0.1: \n",
    "                reward *= 2.0 \n",
    "            elif ret < -0.01 and act > 0.1: \n",
    "                reward -= (act * 10.0) \n",
    "            \n",
    "        self.current_step += 1\n",
    "        return self._get_obs(), reward, False, False, {}\n",
    "\n",
    "# --- MANAGER (UPDATED REGIME LOGIC WITH JUMPS) ---\n",
    "class EnsembleManager:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.dp = DataProcessor(config['TICKERS'], config)\n",
    "        self.agents = {}\n",
    "        self.envs = {}\n",
    "        \n",
    "    def train_specialists(self, verbose=True):\n",
    "        if verbose: print(\"\\n=== 1. TRAINING SPECIALIST AGENTS ===\")\n",
    "        trend_data = self.dp.get_data(self.config['TRAIN_START'], self.config['TRAIN_END'])\n",
    "        \n",
    "        # 1. Trend\n",
    "        env_trend = DummyVecEnv([lambda: TradingEnv(trend_data, self.config, mode='trend')])\n",
    "        env_trend = VecNormalize(env_trend, norm_obs=True, norm_reward=False)\n",
    "        model_trend = PPO(\"MlpPolicy\", env_trend, verbose=0, learning_rate=self.config['LEARNING_RATE'])\n",
    "        model_trend.learn(total_timesteps=self.config['TRAINING_STEPS'])\n",
    "        self.agents['trend'] = model_trend\n",
    "        self.envs['trend'] = env_trend\n",
    "        \n",
    "        # 2. Mean Rev\n",
    "        env_mr = DummyVecEnv([lambda: TradingEnv(trend_data, self.config, mode='mean_rev')]) \n",
    "        env_mr = VecNormalize(env_mr, norm_obs=True, norm_reward=False)\n",
    "        model_mr = PPO(\"MlpPolicy\", env_mr, verbose=0, learning_rate=self.config['LEARNING_RATE'])\n",
    "        model_mr.learn(total_timesteps=self.config['TRAINING_STEPS'])\n",
    "        self.agents['mean_rev'] = model_mr\n",
    "        self.envs['mean_rev'] = env_mr\n",
    "        \n",
    "        # 3. Crisis\n",
    "        crash_data = self.dp.get_crisis_data()\n",
    "        env_crisis = DummyVecEnv([lambda: TradingEnv(crash_data, self.config, mode='crisis')])\n",
    "        env_crisis = VecNormalize(env_crisis, norm_obs=True, norm_reward=False)\n",
    "        model_crisis = PPO(\"MlpPolicy\", env_crisis, verbose=0, learning_rate=self.config['LEARNING_RATE'])\n",
    "        model_crisis.learn(total_timesteps=self.config['TRAINING_STEPS'])\n",
    "        self.agents['crisis'] = model_crisis\n",
    "        self.envs['crisis'] = env_crisis\n",
    "        \n",
    "        if verbose: print(\"=== TRAINING COMPLETE ===\\n\")\n",
    "\n",
    "    def run_backtest(self, start_date=None, end_date=None, plot_results=True):\n",
    "        s_date = start_date if start_date else self.config['TEST_START']\n",
    "        e_date = end_date if end_date else self.config['TEST_END']\n",
    "        \n",
    "        if plot_results: print(f\"=== 2. RUNNING BACKTEST ({s_date} to {e_date}) ===\")\n",
    "        \n",
    "        warmup_dt = pd.Timestamp(s_date) - pd.Timedelta(days=365)\n",
    "        full_data = self.dp.get_data(warmup_dt.strftime('%Y-%m-%d'), e_date)\n",
    "        if full_data.empty: return 0.0\n",
    "        \n",
    "        test_indices = np.where((full_data.index >= s_date) & (full_data.index <= e_date))[0]\n",
    "        if len(test_indices) == 0: return 0.0\n",
    "\n",
    "        portfolio = self.config['INITIAL_BALANCE']\n",
    "        benchmark_equity = self.config['INITIAL_BALANCE'] \n",
    "        holdings = 0\n",
    "        history = []\n",
    "        \n",
    "        # Evaluation Stats\n",
    "        regime_stats = {\n",
    "            'trend': {'days': 0, 'log_ret': 0.0, 'bench_log_ret': 0.0},\n",
    "            'mean_rev': {'days': 0, 'log_ret': 0.0, 'bench_log_ret': 0.0},\n",
    "            'crisis': {'days': 0, 'log_ret': 0.0, 'bench_log_ret': 0.0}\n",
    "        }\n",
    "        \n",
    "        cols = full_data.columns.tolist()\n",
    "        idx_adx = cols.index('adx')\n",
    "        idx_sma = cols.index('dist_sma200')\n",
    "        idx_ret = cols.index('returns')\n",
    "        idx_vol_pct = cols.index('vol_percentile')\n",
    "        idx_raw_vol = cols.index('realized_vol_20d')\n",
    "        idx_di_plus = cols.index('di_plus')\n",
    "        idx_di_minus = cols.index('di_minus')\n",
    "        \n",
    "        # NEW: L-Statistic Index\n",
    "        idx_l_stat = cols.index('l_stat')\n",
    "        \n",
    "        data_vals = full_data.values\n",
    "        dates = full_data.index\n",
    "        window = self.config['WINDOW_SIZE']\n",
    "        \n",
    "        agent_pnls = {'trend': 0.0, 'mean_rev': 0.0, 'crisis': 0.0}\n",
    "        \n",
    "        if plot_results:\n",
    "            print(f\"{'Date':<12} | {'Regime':<12} | {'Active Agent':<10} | {'Raw Act':<8} | {'Scale Act':<10} | {'Portfolio':<10} | {'Bench':<10} | {'Daily Alpha':<11}\")\n",
    "            print(\"-\" * 120)\n",
    "        \n",
    "        for t in test_indices:\n",
    "            obs_raw = data_vals[t-window : t].flatten()\n",
    "            \n",
    "            # --- REGIME LOGIC ---\n",
    "            vol_pct = data_vals[t-1, idx_vol_pct] \n",
    "            raw_vol = data_vals[t-1, idx_raw_vol]\n",
    "            adx = data_vals[t-1, idx_adx]\n",
    "            sma_dist = data_vals[t-1, idx_sma]\n",
    "            di_plus = data_vals[t-1, idx_di_plus]\n",
    "            di_minus = data_vals[t-1, idx_di_minus]\n",
    "            \n",
    "            # NEW: Jump Detection\n",
    "            l_stat = data_vals[t-1, idx_l_stat]\n",
    "            \n",
    "            # Thresholds for Daily Data (Relaxed slightly from 4.0 due to lower freq)\n",
    "            is_bullish_jump = (l_stat > 3.5)\n",
    "            is_bearish_jump = (l_stat < -3.5)\n",
    "            \n",
    "            is_extreme_vol = (vol_pct > 0.90)\n",
    "            is_crash = (sma_dist < -0.10)\n",
    "            is_bull_trend = (adx > self.config['ADX_THRESHOLD']) and (di_plus > di_minus)\n",
    "            is_bear_trend = (adx > self.config['ADX_THRESHOLD']) and (di_minus > di_plus)\n",
    "            \n",
    "            # PRIORITY LOGIC:\n",
    "            # 1. Bearish Jump (Immediate Panic) -> CRISIS/BEAR\n",
    "            # 2. Bullish Jump (Immediate Breakout) -> TREND\n",
    "            # 3. Standard Logic\n",
    "            \n",
    "            if is_bearish_jump:\n",
    "                regime, active_agent_name = \"JUMP_BEAR\", \"crisis\"\n",
    "            elif is_bullish_jump:\n",
    "                regime, active_agent_name = \"JUMP_BULL\", \"trend\"\n",
    "            elif is_extreme_vol or is_crash: \n",
    "                regime, active_agent_name = \"CRISIS\", \"crisis\"\n",
    "            elif is_bear_trend:\n",
    "                regime, active_agent_name = \"BEAR_TREND\", \"crisis\"\n",
    "            elif is_bull_trend: \n",
    "                regime, active_agent_name = \"TREND\", \"trend\"\n",
    "            else:\n",
    "                regime, active_agent_name = \"CHOP\", \"mean_rev\"\n",
    "                \n",
    "            # Predict\n",
    "            agent = self.agents[active_agent_name]\n",
    "            norm_env = self.envs[active_agent_name]\n",
    "            obs_norm = norm_env.normalize_obs(obs_raw)\n",
    "            action, _ = agent.predict(obs_norm, deterministic=True)\n",
    "            \n",
    "            # Exec\n",
    "            mkt_ret = data_vals[t, idx_ret]\n",
    "            raw_action = action[0]\n",
    "            \n",
    "            # Vol Targeting\n",
    "            vol_scaler = 1.0\n",
    "            if self.config['USE_VOL_TARGETING'] and raw_vol > 0.01:\n",
    "                vol_scaler = self.config['TARGET_VOL'] / raw_vol\n",
    "            vol_scaler = np.clip(vol_scaler, 0.1, 2.0)\n",
    "            \n",
    "            # --- DEFENSIVE OVERRIDE ---\n",
    "            if self.config['LONG_ONLY']:\n",
    "                if regime in ['BEAR_TREND', 'JUMP_BEAR']:\n",
    "                    # Strict safety on confirmed downtrends or negative shocks\n",
    "                    scaled_action = 0.0\n",
    "                elif regime == 'CRISIS':\n",
    "                    # Allow trading in panic (bottom fishing) but not sustained bear\n",
    "                    scaled_action = raw_action * self.config['ACTION_SCALER'] * vol_scaler\n",
    "                else:\n",
    "                    scaled_action = raw_action * self.config['ACTION_SCALER'] * vol_scaler\n",
    "            else:\n",
    "                scaled_action = raw_action * self.config['ACTION_SCALER'] * vol_scaler\n",
    "\n",
    "            if self.config['LONG_ONLY']: scaled_action = np.clip(scaled_action, 0, 10)\n",
    "            \n",
    "            # Trend Filter\n",
    "            if self.config['SMA_TREND_FILTER'] and active_agent_name == 'trend':\n",
    "                if sma_dist < 0: scaled_action = np.clip(scaled_action, -10, 0)\n",
    "                elif sma_dist > 0: scaled_action = np.clip(scaled_action, 0, 10)\n",
    "            \n",
    "            position_size = np.clip(scaled_action, -self.config['MAX_LEVERAGE'], self.config['MAX_LEVERAGE'])\n",
    "            \n",
    "            # PnL\n",
    "            cost = abs(position_size - holdings) * self.config['FEES']\n",
    "            lev_cost = max(0, abs(position_size)-1) * self.config['BORROW_RATE']\n",
    "            \n",
    "            step_pnl_pct = (position_size * mkt_ret) - cost - lev_cost\n",
    "            step_pnl_dollars = portfolio * step_pnl_pct\n",
    "            \n",
    "            portfolio *= (1 + step_pnl_pct)\n",
    "            benchmark_equity *= (1 + mkt_ret)\n",
    "            holdings = position_size\n",
    "            \n",
    "            agent_pnls[active_agent_name] += step_pnl_dollars\n",
    "            \n",
    "            # Stats\n",
    "            regime_stats[active_agent_name]['days'] += 1\n",
    "            regime_stats[active_agent_name]['log_ret'] += np.log1p(step_pnl_pct)\n",
    "            regime_stats[active_agent_name]['bench_log_ret'] += np.log1p(mkt_ret)\n",
    "            \n",
    "            alpha_bps = (step_pnl_pct - mkt_ret) * 10000\n",
    "            \n",
    "            if plot_results and t % 20 == 0: \n",
    "                print(f\"{str(dates[t].date()):<12} | {regime:<12} | {active_agent_name:<10} | {raw_action:<8.2f} | {position_size:<10.2f} | {portfolio:<10.0f} | {benchmark_equity:<10.0f} | {alpha_bps:>8.0f} bps\")\n",
    "                \n",
    "            history.append({\n",
    "                'Date': dates[t],\n",
    "                'Portfolio': portfolio,\n",
    "                'Regime': regime,\n",
    "                'Agent': active_agent_name,\n",
    "                'Return': step_pnl_pct,\n",
    "                'Benchmark': mkt_ret,\n",
    "                'Scale Act': position_size,\n",
    "                'Trend_PnL': agent_pnls['trend'],\n",
    "                'MeanRev_PnL': agent_pnls['mean_rev'],\n",
    "                'Crisis_PnL': agent_pnls['crisis']\n",
    "            })\n",
    "            \n",
    "        res = pd.DataFrame(history).set_index('Date')\n",
    "        total_ret = (portfolio / self.config['INITIAL_BALANCE']) - 1\n",
    "        \n",
    "        if plot_results:\n",
    "            bench_ret = (1 + res['Benchmark']).cumprod().iloc[-1] - 1\n",
    "            print(f\"\\n=== FINAL REPORT: {total_ret:.2%} (Bench: {bench_ret:.2%}) ===\")\n",
    "            \n",
    "            print(\"\\n=== AGENT PERFORMANCE BREAKDOWN (vs Benchmark in same period) ===\")\n",
    "            print(f\"{'Agent':<12} | {'Days':<6} | {'Agent Ret':<12} | {'Bench Ret':<12} | {'Alpha':<12}\")\n",
    "            print(\"-\" * 65)\n",
    "            for agent_name, stats in regime_stats.items():\n",
    "                if stats['days'] > 0:\n",
    "                    agent_ret = np.exp(stats['log_ret']) - 1\n",
    "                    bench_ret = np.exp(stats['bench_log_ret']) - 1\n",
    "                    alpha = agent_ret - bench_ret\n",
    "                    print(f\"{agent_name:<12} | {stats['days']:<6} | {agent_ret:>11.2%} | {bench_ret:>11.2%} | {alpha:>11.2%}\")\n",
    "                else:\n",
    "                    print(f\"{agent_name:<12} | {0:<6} | {'N/A':>11} | {'N/A':>11} | {'0.00%':>11}\")\n",
    "            print(\"-\" * 65)\n",
    "            \n",
    "            self.plot_dashboard(res)\n",
    "            \n",
    "        return total_ret\n",
    "\n",
    "    def plot_dashboard(self, res):\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(14, 18), sharex=True, gridspec_kw={'height_ratios': [3, 2, 2, 2]})\n",
    "        plt.subplots_adjust(hspace=0.2)\n",
    "        \n",
    "        res['Bench_Equity'] = (1 + res['Benchmark']).cumprod() * self.config['INITIAL_BALANCE']\n",
    "        ax0 = axes[0]\n",
    "        ax0.plot(res.index, res['Portfolio'], label='Ensemble AI', color='black', linewidth=2)\n",
    "        ax0.plot(res.index, res['Bench_Equity'], label='Buy & Hold', color='gray', linestyle='--', alpha=0.6)\n",
    "        ax0.set_title(f\"Equity Curve: {self.config['TARGET_ASSET']}\", fontweight='bold')\n",
    "        ax0.set_ylabel(\"Portfolio Value ($)\")\n",
    "        ax0.grid(True, alpha=0.3)\n",
    "        \n",
    "        y_min, y_max = ax0.get_ylim()\n",
    "        ax0.fill_between(res.index, y_min, y_max, where=(res['Agent'] == 'trend'), color='green', alpha=0.1, label='Trend Regime')\n",
    "        ax0.fill_between(res.index, y_min, y_max, where=(res['Agent'] == 'mean_rev'), color='orange', alpha=0.15, label='Chop Regime')\n",
    "        ax0.fill_between(res.index, y_min, y_max, where=(res['Agent'] == 'crisis'), color='red', alpha=0.15, label='Crisis/Bear Regime')\n",
    "        ax0.legend(loc='upper left', frameon=True)\n",
    "\n",
    "        ax1 = axes[1]\n",
    "        strat_peak = res['Portfolio'].cummax()\n",
    "        strat_dd = (res['Portfolio'] - strat_peak) / strat_peak\n",
    "        ax1.fill_between(res.index, strat_dd, 0, color='red', alpha=0.3, label='Strategy Drawdown')\n",
    "        ax1.set_ylabel(\"Drawdown %\")\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        ax2 = axes[2]\n",
    "        ax2.plot(res.index, res['Trend_PnL'], label='Trend Agent', color='green', linewidth=1.5)\n",
    "        ax2.plot(res.index, res['MeanRev_PnL'], label='Mean Rev Agent', color='orange', linewidth=1.5)\n",
    "        ax2.plot(res.index, res['Crisis_PnL'], label='Crisis Agent', color='red', linewidth=1.5)\n",
    "        ax2.set_ylabel(\"Profit Contrib ($)\")\n",
    "        ax2.legend(loc='upper left')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        ax3 = axes[3]\n",
    "        colors = ['forestgreen' if r > 0 else 'firebrick' for r in res['Return']]\n",
    "        ax3.bar(res.index, res['Scale Act'], color=colors, width=1.5)\n",
    "        ax3.set_ylabel(\"Exposure\")\n",
    "        ax3.set_ylim(-0.1, self.config['MAX_LEVERAGE']*1.1)\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "class HyperparameterOptimizer:\n",
    "    def __init__(self, tickers, target):\n",
    "        self.tickers = tickers\n",
    "        self.target = target\n",
    "        \n",
    "    def optimize(self, train_start, train_end):\n",
    "        print(f\"\\n>>> STARTING HYPERPARAMETER OPTIMIZATION FOR {self.target} <<<\")\n",
    "        \n",
    "        # Grid Search Space\n",
    "        param_grid = {\n",
    "            \"WINDOW_SIZE\": [20, 60],\n",
    "            \"ADX_THRESHOLD\": [20, 25],\n",
    "            \"TARGET_VOL\": [0.20, 0.40] \n",
    "        }\n",
    "        \n",
    "        best_ret = -np.inf\n",
    "        best_config = None\n",
    "        \n",
    "        keys, values = zip(*param_grid.items())\n",
    "        combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "        \n",
    "        for i, params in enumerate(combinations):\n",
    "            print(f\"Testing Config {i+1}/{len(combinations)}: {params}\")\n",
    "            \n",
    "            # Create Config Copy\n",
    "            trial_config = DEFAULT_CONFIG.copy()\n",
    "            trial_config.update(params)\n",
    "            trial_config['TICKERS'] = self.tickers\n",
    "            trial_config['TARGET_ASSET'] = self.target\n",
    "            trial_config['TRAIN_START'] = train_start\n",
    "            trial_config['TRAIN_END'] = train_end\n",
    "            \n",
    "            # We use the last 1 year of 'Training' data as Validation for optimization\n",
    "            # In a real scenario, you'd split Train/Val properly.\n",
    "            # Here we just run a quick backtest on the TRAIN period to see fit.\n",
    "            trial_config['TEST_START'] = str(int(train_end[:4]) - 1) + train_end[4:]\n",
    "            trial_config['TEST_END'] = train_end\n",
    "            \n",
    "            # Fast Training\n",
    "            trial_config['TRAINING_STEPS'] = 10000 \n",
    "            \n",
    "            mgr = EnsembleManager(trial_config)\n",
    "            mgr.train_specialists(verbose=False)\n",
    "            ret = mgr.run_backtest(plot_results=False)\n",
    "            \n",
    "            print(f\"  -> Return: {ret:.2%}\")\n",
    "            \n",
    "            if ret > best_ret:\n",
    "                best_ret = ret\n",
    "                best_config = params\n",
    "                \n",
    "        print(f\"\\n>>> BEST PARAMETERS FOUND: {best_config} (Ret: {best_ret:.2%}) <<<\")\n",
    "        return best_config\n",
    "\n",
    "def run_system(tickers, target, start, end):\n",
    "    config = DEFAULT_CONFIG.copy()\n",
    "    config['TICKERS'] = tickers\n",
    "    config['TARGET_ASSET'] = target\n",
    "    config['TEST_START'] = start\n",
    "    config['TEST_END'] = end\n",
    "    \n",
    "    # Safety Defaults for Single Stock\n",
    "    if target != \"SPY\":\n",
    "        config['LONG_ONLY'] = True\n",
    "        config['MAX_LEVERAGE'] = 1.0\n",
    "        config['TARGET_VOL'] = 0.40\n",
    "        config['ADX_THRESHOLD'] = 25\n",
    "        config['TRAINING_STEPS'] = 50000 \n",
    "        config['USE_VOL_TARGETING'] = False \n",
    "        config['ACTION_SCALER'] = 10.0 \n",
    "\n",
    "            # if optimize:\n",
    "    # Run optimization on the period PRIOR to the test start\n",
    "    opt = HyperparameterOptimizer(tickers, target)\n",
    "    # Use 2020-2023 as optimization/validation window\n",
    "    best_params = opt.optimize(\"2016-01-01\", start) \n",
    "    config.update(best_params)\n",
    "    \n",
    "    print(\"\\n>>> INITIALIZING TRINITY V3 (JUMP DETECTOR ENABLED) <<<\")\n",
    "    mgr = EnsembleManager(config)\n",
    "    mgr.train_specialists()\n",
    "    mgr.run_backtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea7fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> STARTING HYPERPARAMETER OPTIMIZATION FOR GOOG <<<\n",
      "Testing Config 1/8: {'WINDOW_SIZE': 20, 'ADX_THRESHOLD': 20, 'TARGET_VOL': 0.2}\n",
      "Fetching data for: ['SHY', '^VIX', 'GOOG'] (2016-01-01 to 2024-01-22)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DEFAULT_CONFIG = {\n",
    "    # Assets\n",
    "    \"TICKERS\": [\"SPY\", \"IWM\", \"^VIX\", \"SHY\"], \n",
    "    \"TARGET_ASSET\": \"SPY\",\n",
    "    \n",
    "    # Dates\n",
    "    \"TRAIN_START\": \"2015-01-01\",\n",
    "    \"TRAIN_END\": \"2023-12-31\",\n",
    "    \"TEST_START\": \"2024-01-02\",\n",
    "    \"TEST_END\": \"2025-05-05\",\n",
    "    \n",
    "    # Crisis Training Periods\n",
    "    \"CRISIS_PERIODS\": [\n",
    "        (\"2018-10-01\", \"2019-01-01\"), # Volmageddon\n",
    "        (\"2020-01-01\", \"2020-05-01\"), # COVID\n",
    "        (\"2022-01-01\", \"2022-12-31\"), # Bear\n",
    "    ],\n",
    "    \n",
    "    # Hyperparameters\n",
    "    \"WINDOW_SIZE\": 60, \n",
    "    \"ADX_THRESHOLD\": 25,\n",
    "    \"TARGET_VOL\": 0.40,\n",
    "    \n",
    "    # Fixed Params\n",
    "    \"BB_STD\": 2.0,\n",
    "    \"LEARNING_RATE\": 3e-4,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"TRAINING_STEPS\": 50000, \n",
    "    \"INITIAL_BALANCE\": 100000,\n",
    "    \"FEES\": 0.0005,\n",
    "    \"BORROW_RATE\": 0.0002, \n",
    "    \"ACTION_SCALER\": 5.0,\n",
    "    \"MAX_LEVERAGE\": 1.0, \n",
    "    \"USE_VOL_TARGETING\": True,\n",
    "    \"SMA_TREND_FILTER\": True,\n",
    "    \"LONG_ONLY\": False \n",
    "}\n",
    "\n",
    "# --- DATA PROCESSOR ---\n",
    "class DataProcessor:\n",
    "    def __init__(self, tickers, config):\n",
    "        self.tickers = list(set(tickers))\n",
    "        self.config = config\n",
    "        \n",
    "    def download(self, start, end):\n",
    "        try:\n",
    "            if self.config['TARGET_ASSET'] not in self.tickers:\n",
    "                self.tickers.append(self.config['TARGET_ASSET'])\n",
    "                \n",
    "            print(f\"Fetching data for: {self.tickers} ({start} to {end})\")\n",
    "            data = yf.download(self.tickers, start=start, end=end, progress=False)\n",
    "            \n",
    "            if isinstance(data.columns, pd.MultiIndex):\n",
    "                if 'Close' in data.columns.levels[0]: data = data.xs('Close', level=0, axis=1)\n",
    "                elif 'Adj Close' in data.columns.levels[0]: data = data.xs('Adj Close', level=0, axis=1)\n",
    "                elif 'Close' in data.columns.levels[1]: data = data.xs('Close', level=1, axis=1)\n",
    "            \n",
    "            if isinstance(data, pd.Series): \n",
    "                data = data.to_frame()\n",
    "                if self.config['TARGET_ASSET'] not in data.columns:\n",
    "                    data.columns = [self.config['TARGET_ASSET']]\n",
    "            \n",
    "            ohlc = yf.download(self.config['TARGET_ASSET'], start=start, end=end, progress=False)\n",
    "            return data, ohlc\n",
    "        except Exception as e:\n",
    "            print(f\"Data Download Error: {e}\")\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    def calculate_lee_mykland(self, df, window=20):\n",
    "        log_ret = np.log(df / df.shift(1))\n",
    "        abs_ret = np.abs(log_ret)\n",
    "        bv_terms = abs_ret * abs_ret.shift(1)\n",
    "        local_vol = np.sqrt((np.pi / 2) * bv_terms.rolling(window=window).mean())\n",
    "        l_stat = log_ret / (local_vol + 1e-9)\n",
    "        return l_stat.fillna(0)\n",
    "\n",
    "    def add_features(self, df, ohlc):\n",
    "        target = self.config['TARGET_ASSET']\n",
    "        if df.empty or target not in df.columns: return pd.DataFrame()\n",
    "        \n",
    "        df = df.copy()\n",
    "        df['returns'] = df[target].pct_change()\n",
    "        \n",
    "        # JUMP DETECTION\n",
    "        l_stat = self.calculate_lee_mykland(df[target], window=20)\n",
    "        df['l_stat'] = l_stat\n",
    "        \n",
    "        # Trend\n",
    "        high = ohlc['High']\n",
    "        low = ohlc['Low']\n",
    "        close = ohlc['Close']\n",
    "        df['tr'] = np.maximum(high - low, np.maximum(abs(high - close.shift(1)), abs(low - close.shift(1))))\n",
    "        df['dm_plus'] = np.where((high - high.shift(1)) > (low.shift(1) - low), np.maximum(high - high.shift(1), 0), 0)\n",
    "        df['dm_minus'] = np.where((low.shift(1) - low) > (high - high.shift(1)), np.maximum(low.shift(1) - low, 0), 0)\n",
    "        \n",
    "        window = 14\n",
    "        df['tr_s'] = df['tr'].rolling(window).mean()\n",
    "        df['dp_s'] = df['dm_plus'].rolling(window).mean()\n",
    "        df['dm_s'] = df['dm_minus'].rolling(window).mean()\n",
    "        df['di_plus'] = 100 * (df['dp_s'] / df['tr_s'])\n",
    "        df['di_minus'] = 100 * (df['dm_s'] / df['tr_s'])\n",
    "        df['dx'] = 100 * abs(df['di_plus'] - df['di_minus']) / (df['di_plus'] + df['di_minus'])\n",
    "        df['adx'] = df['dx'].rolling(window).mean()\n",
    "        \n",
    "        # Mean Reversion\n",
    "        sma = df[target].rolling(20).mean()\n",
    "        std = df[target].rolling(20).std()\n",
    "        df['bb_width'] = (std * 2 * 2) / sma\n",
    "        df['pct_b'] = (df[target] - (sma - 2*std)) / (4*std)\n",
    "        \n",
    "        # Crisis\n",
    "        if '^VIX' in df.columns: df['vix_norm'] = (df['^VIX'] - 15) / 40\n",
    "        else: df['vix_norm'] = 0\n",
    "            \n",
    "        sma200 = df[target].rolling(200).mean()\n",
    "        df['dist_sma200'] = (df[target] - sma200) / sma200\n",
    "        \n",
    "        # Volatility\n",
    "        df['realized_vol_20d'] = df['returns'].rolling(20).std() * np.sqrt(252)\n",
    "        df['vol_percentile'] = df['realized_vol_20d'].rolling(252).rank(pct=True)\n",
    "        \n",
    "        return df.fillna(0)\n",
    "\n",
    "    def get_data(self, start, end):\n",
    "        df, ohlc = self.download(start, end)\n",
    "        return self.add_features(df, ohlc)\n",
    "\n",
    "    def get_crisis_data(self):\n",
    "        dfs = []\n",
    "        for s, e in self.config['CRISIS_PERIODS']:\n",
    "            d, o = self.download(s, e)\n",
    "            dfs.append(self.add_features(d, o))\n",
    "        return pd.concat(dfs).reset_index(drop=True).fillna(0)\n",
    "\n",
    "# --- ENVIRONMENT (REPLACED MEAN REV WITH ACCUMULATION) ---\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, df, config, mode='trend'):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.mode = mode \n",
    "        self.n_features = df.shape[1]\n",
    "        self.window = config['WINDOW_SIZE']\n",
    "        self.current_step = self.window\n",
    "        \n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.window * self.n_features,), dtype=np.float32)\n",
    "        \n",
    "        self.data = df.values.astype(np.float32)\n",
    "        self.cols = df.columns.tolist()\n",
    "        self.idx_sma = self.cols.index('dist_sma200') if 'dist_sma200' in self.cols else -1\n",
    "        self.idx_pct_b = self.cols.index('pct_b') if 'pct_b' in self.cols else -1\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.current_step = self.window\n",
    "        return self._get_obs(), {}\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        return self.data[self.current_step-self.window : self.current_step].flatten()\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.current_step >= len(self.df) - 1:\n",
    "            return self._get_obs(), 0, True, False, {}\n",
    "            \n",
    "        act = np.clip(action[0], -1, 1)\n",
    "        ret = self.data[self.current_step, 0] \n",
    "        \n",
    "        reward = 0\n",
    "        if self.mode == 'trend':\n",
    "            reward = act * ret * 100\n",
    "            if self.idx_sma != -1:\n",
    "                sma_dist = self.data[self.current_step, self.idx_sma]\n",
    "                if sma_dist > 0 and act > 0.1: reward += 0.05 * act \n",
    "                elif sma_dist < 0 and act < -0.1: reward += 0.05 * abs(act)\n",
    "                \n",
    "        elif self.mode == 'accumulation': # REPLACED MEAN_REV\n",
    "            # OBJECTIVE: Maximize exposure to drift, Minimize Jitter (Fees)\n",
    "            \n",
    "            # 1. Base Profit\n",
    "            reward = (act * ret * 100) \n",
    "            \n",
    "            # 2. Accumulation Bias: Reward holding > 50% exposure\n",
    "            # This teaches the agent that \"Chop\" in training data is generally up-drift\n",
    "            if act > 0.5:\n",
    "                reward += 0.05 * act\n",
    "            \n",
    "            # 3. Penalty for Shorting in Accumulation Mode\n",
    "            # Unless the return is violently negative, shorting chop is bad\n",
    "            if act < 0:\n",
    "                reward -= 0.1 * abs(act)\n",
    "\n",
    "        elif self.mode == 'crisis':\n",
    "            reward = (act * ret * 100)\n",
    "            if ret < -0.01 and act < -0.1: reward *= 2.0 \n",
    "            elif ret < -0.01 and act > 0.1: reward -= (act * 10.0) \n",
    "            \n",
    "        self.current_step += 1\n",
    "        return self._get_obs(), reward, False, False, {}\n",
    "\n",
    "# --- MANAGER ---\n",
    "class EnsembleManager:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.dp = DataProcessor(config['TICKERS'], config)\n",
    "        self.agents = {}\n",
    "        self.envs = {}\n",
    "        \n",
    "    def train_specialists(self, verbose=True):\n",
    "        if verbose: print(\"\\n=== 1. TRAINING SPECIALIST AGENTS ===\")\n",
    "        trend_data = self.dp.get_data(self.config['TRAIN_START'], self.config['TRAIN_END'])\n",
    "        \n",
    "        # 1. Trend\n",
    "        env_trend = DummyVecEnv([lambda: TradingEnv(trend_data, self.config, mode='trend')])\n",
    "        env_trend = VecNormalize(env_trend, norm_obs=True, norm_reward=False)\n",
    "        model_trend = PPO(\"MlpPolicy\", env_trend, verbose=0, learning_rate=self.config['LEARNING_RATE'])\n",
    "        model_trend.learn(total_timesteps=self.config['TRAINING_STEPS'])\n",
    "        self.agents['trend'] = model_trend\n",
    "        self.envs['trend'] = env_trend\n",
    "        \n",
    "        # 2. Accumulation (Formerly Mean Rev)\n",
    "        # We train this on the same trend data, but with the new \"Accumulation\" reward function\n",
    "        env_acc = DummyVecEnv([lambda: TradingEnv(trend_data, self.config, mode='accumulation')]) \n",
    "        env_acc = VecNormalize(env_acc, norm_obs=True, norm_reward=False)\n",
    "        model_acc = PPO(\"MlpPolicy\", env_acc, verbose=0, learning_rate=self.config['LEARNING_RATE'])\n",
    "        model_acc.learn(total_timesteps=self.config['TRAINING_STEPS'])\n",
    "        self.agents['accumulation'] = model_acc\n",
    "        self.envs['accumulation'] = env_acc\n",
    "        \n",
    "        # 3. Crisis\n",
    "        crash_data = self.dp.get_crisis_data()\n",
    "        env_crisis = DummyVecEnv([lambda: TradingEnv(crash_data, self.config, mode='crisis')])\n",
    "        env_crisis = VecNormalize(env_crisis, norm_obs=True, norm_reward=False)\n",
    "        model_crisis = PPO(\"MlpPolicy\", env_crisis, verbose=0, learning_rate=self.config['LEARNING_RATE'])\n",
    "        model_crisis.learn(total_timesteps=self.config['TRAINING_STEPS'])\n",
    "        self.agents['crisis'] = model_crisis\n",
    "        self.envs['crisis'] = env_crisis\n",
    "        \n",
    "        if verbose: print(\"=== TRAINING COMPLETE ===\\n\")\n",
    "\n",
    "    def run_backtest(self, start_date=None, end_date=None, plot_results=True):\n",
    "        s_date = start_date if start_date else self.config['TEST_START']\n",
    "        e_date = end_date if end_date else self.config['TEST_END']\n",
    "        \n",
    "        if plot_results: print(f\"=== 2. RUNNING BACKTEST ({s_date} to {e_date}) ===\")\n",
    "        \n",
    "        warmup_dt = pd.Timestamp(s_date) - pd.Timedelta(days=365)\n",
    "        full_data = self.dp.get_data(warmup_dt.strftime('%Y-%m-%d'), e_date)\n",
    "        if full_data.empty: return 0.0\n",
    "        \n",
    "        test_indices = np.where((full_data.index >= s_date) & (full_data.index <= e_date))[0]\n",
    "        if len(test_indices) == 0: return 0.0\n",
    "\n",
    "        portfolio = self.config['INITIAL_BALANCE']\n",
    "        benchmark_equity = self.config['INITIAL_BALANCE'] \n",
    "        holdings = 0\n",
    "        history = []\n",
    "        \n",
    "        regime_stats = {\n",
    "            'trend': {'days': 0, 'log_ret': 0.0, 'bench_log_ret': 0.0},\n",
    "            'accumulation': {'days': 0, 'log_ret': 0.0, 'bench_log_ret': 0.0}, # Renamed\n",
    "            'crisis': {'days': 0, 'log_ret': 0.0, 'bench_log_ret': 0.0}\n",
    "        }\n",
    "        \n",
    "        cols = full_data.columns.tolist()\n",
    "        idx_adx = cols.index('adx')\n",
    "        idx_sma = cols.index('dist_sma200')\n",
    "        idx_ret = cols.index('returns')\n",
    "        idx_vol_pct = cols.index('vol_percentile')\n",
    "        idx_raw_vol = cols.index('realized_vol_20d')\n",
    "        idx_di_plus = cols.index('di_plus')\n",
    "        idx_di_minus = cols.index('di_minus')\n",
    "        idx_l_stat = cols.index('l_stat')\n",
    "        idx_pct_b = cols.index('pct_b')\n",
    "        \n",
    "        data_vals = full_data.values\n",
    "        dates = full_data.index\n",
    "        window = self.config['WINDOW_SIZE']\n",
    "        \n",
    "        agent_pnls = {'trend': 0.0, 'accumulation': 0.0, 'crisis': 0.0}\n",
    "        \n",
    "        if plot_results:\n",
    "            print(f\"{'Date':<12} | {'Regime':<12} | {'Active Agent':<12} | {'Raw Act':<8} | {'Scale Act':<10} | {'Portfolio':<10} | {'Bench':<10} | {'Daily Alpha':<11}\")\n",
    "            print(\"-\" * 120)\n",
    "        \n",
    "        for t in test_indices:\n",
    "            obs_raw = data_vals[t-window : t].flatten()\n",
    "            \n",
    "            vol_pct = data_vals[t-1, idx_vol_pct] \n",
    "            raw_vol = data_vals[t-1, idx_raw_vol]\n",
    "            adx = data_vals[t-1, idx_adx]\n",
    "            sma_dist = data_vals[t-1, idx_sma]\n",
    "            di_plus = data_vals[t-1, idx_di_plus]\n",
    "            di_minus = data_vals[t-1, idx_di_minus]\n",
    "            l_stat = data_vals[t-1, idx_l_stat]\n",
    "            \n",
    "            is_bullish_jump = (l_stat > 3.5)\n",
    "            is_bearish_jump = (l_stat < -3.5)\n",
    "            is_extreme_vol = (vol_pct > 0.90)\n",
    "            is_crash = (sma_dist < -0.10)\n",
    "            is_bull_trend = (adx > self.config['ADX_THRESHOLD']) and (di_plus > di_minus)\n",
    "            is_bear_trend = (adx > self.config['ADX_THRESHOLD']) and (di_minus > di_plus)\n",
    "            \n",
    "            # PRIORITY LOGIC\n",
    "            if is_bearish_jump:\n",
    "                regime, active_agent_name = \"JUMP_BEAR\", \"crisis\"\n",
    "            elif is_bullish_jump:\n",
    "                regime, active_agent_name = \"JUMP_BULL\", \"trend\"\n",
    "            elif is_extreme_vol or is_crash: \n",
    "                regime, active_agent_name = \"CRISIS\", \"crisis\"\n",
    "            elif is_bear_trend:\n",
    "                regime, active_agent_name = \"BEAR_TREND\", \"crisis\"\n",
    "            elif is_bull_trend: \n",
    "                regime, active_agent_name = \"TREND\", \"trend\"\n",
    "            else:\n",
    "                regime, active_agent_name = \"ACCUMULATION\", \"accumulation\" # Changed from CHOP/mean_rev\n",
    "                \n",
    "            # Predict\n",
    "            agent = self.agents[active_agent_name]\n",
    "            norm_env = self.envs[active_agent_name]\n",
    "            obs_norm = norm_env.normalize_obs(obs_raw)\n",
    "            action, _ = agent.predict(obs_norm, deterministic=True)\n",
    "            \n",
    "            # Exec\n",
    "            mkt_ret = data_vals[t, idx_ret]\n",
    "            raw_action = action[0]\n",
    "            \n",
    "            # --- OVERRIDES ---\n",
    "            \n",
    "            # 1. JUMP MOMENTUM\n",
    "            if regime == 'JUMP_BULL':\n",
    "                raw_action = 1.0\n",
    "            \n",
    "            # 2. Trend Alignment\n",
    "            if active_agent_name == 'trend' and raw_action < 0:\n",
    "                raw_action = 0.5 \n",
    "                \n",
    "            # 3. Accumulation Stability Logic\n",
    "            if active_agent_name == 'accumulation':\n",
    "                # If we are in Accumulation (Chop), and above SMA200 (Bull Market),\n",
    "                # We enforce a \"Hold\" bias to prevent fee bleed from jitter.\n",
    "                if sma_dist > 0:\n",
    "                    # If Agent says Long, we pin to 1.0 to capture full drift\n",
    "                    if raw_action > 0.2: \n",
    "                        raw_action = 1.0\n",
    "                    # If Agent says Neutral/Short, we force a \"Core Hold\" of 0.5\n",
    "                    # unless it's a deep sell (-0.8)\n",
    "                    elif raw_action > -0.5:\n",
    "                        raw_action = 0.5\n",
    "            \n",
    "            # Vol Targeting\n",
    "            vol_scaler = 1.0\n",
    "            if self.config['USE_VOL_TARGETING'] and raw_vol > 0.01:\n",
    "                vol_scaler = self.config['TARGET_VOL'] / raw_vol\n",
    "            vol_scaler = np.clip(vol_scaler, 0.1, 2.0)\n",
    "            \n",
    "            # --- DEFENSIVE OVERRIDE ---\n",
    "            if self.config['LONG_ONLY']:\n",
    "                if regime in ['BEAR_TREND', 'JUMP_BEAR']:\n",
    "                    scaled_action = 0.0\n",
    "                elif regime == 'CRISIS':\n",
    "                    scaled_action = raw_action * self.config['ACTION_SCALER'] * vol_scaler\n",
    "                else:\n",
    "                    scaled_action = raw_action * self.config['ACTION_SCALER'] * vol_scaler\n",
    "            else:\n",
    "                scaled_action = raw_action * self.config['ACTION_SCALER'] * vol_scaler\n",
    "\n",
    "            if self.config['LONG_ONLY']: scaled_action = np.clip(scaled_action, 0, 10)\n",
    "            \n",
    "            # Trend Filter\n",
    "            if self.config['SMA_TREND_FILTER'] and active_agent_name == 'trend':\n",
    "                if sma_dist < 0: scaled_action = np.clip(scaled_action, -10, 0)\n",
    "                elif sma_dist > 0: scaled_action = np.clip(scaled_action, 0, 10)\n",
    "            \n",
    "            position_size = np.clip(scaled_action, -self.config['MAX_LEVERAGE'], self.config['MAX_LEVERAGE'])\n",
    "            \n",
    "            # PnL\n",
    "            cost = abs(position_size - holdings) * self.config['FEES']\n",
    "            lev_cost = max(0, abs(position_size)-1) * self.config['BORROW_RATE']\n",
    "            \n",
    "            step_pnl_pct = (position_size * mkt_ret) - cost - lev_cost\n",
    "            step_pnl_dollars = portfolio * step_pnl_pct\n",
    "            \n",
    "            portfolio *= (1 + step_pnl_pct)\n",
    "            benchmark_equity *= (1 + mkt_ret)\n",
    "            holdings = position_size\n",
    "            \n",
    "            agent_pnls[active_agent_name] += step_pnl_dollars\n",
    "            \n",
    "            # Stats\n",
    "            regime_stats[active_agent_name]['days'] += 1\n",
    "            regime_stats[active_agent_name]['log_ret'] += np.log1p(step_pnl_pct)\n",
    "            regime_stats[active_agent_name]['bench_log_ret'] += np.log1p(mkt_ret)\n",
    "            \n",
    "            alpha_bps = (step_pnl_pct - mkt_ret) * 10000\n",
    "            \n",
    "            if plot_results and t % 20 == 0: \n",
    "                print(f\"{str(dates[t].date()):<12} | {regime:<12} | {active_agent_name:<12} | {raw_action:<8.2f} | {position_size:<10.2f} | {portfolio:<10.0f} | {benchmark_equity:<10.0f} | {alpha_bps:>8.0f} bps\")\n",
    "                \n",
    "            history.append({\n",
    "                'Date': dates[t],\n",
    "                'Portfolio': portfolio,\n",
    "                'Regime': regime,\n",
    "                'Agent': active_agent_name,\n",
    "                'Return': step_pnl_pct,\n",
    "                'Benchmark': mkt_ret,\n",
    "                'Scale Act': position_size,\n",
    "                'Trend_PnL': agent_pnls['trend'],\n",
    "                'MeanRev_PnL': agent_pnls['accumulation'],\n",
    "                'Crisis_PnL': agent_pnls['crisis']\n",
    "            })\n",
    "            \n",
    "        res = pd.DataFrame(history).set_index('Date')\n",
    "        total_ret = (portfolio / self.config['INITIAL_BALANCE']) - 1\n",
    "        \n",
    "        if plot_results:\n",
    "            bench_ret = (1 + res['Benchmark']).cumprod().iloc[-1] - 1\n",
    "            print(f\"\\n=== FINAL REPORT: {total_ret:.2%} (Bench: {bench_ret:.2%}) ===\")\n",
    "            \n",
    "            print(\"\\n=== AGENT PERFORMANCE BREAKDOWN (vs Benchmark in same period) ===\")\n",
    "            print(f\"{'Agent':<12} | {'Days':<6} | {'Agent Ret':<12} | {'Bench Ret':<12} | {'Alpha':<12}\")\n",
    "            print(\"-\" * 65)\n",
    "            for agent_name, stats in regime_stats.items():\n",
    "                if stats['days'] > 0:\n",
    "                    agent_ret = np.exp(stats['log_ret']) - 1\n",
    "                    bench_ret = np.exp(stats['bench_log_ret']) - 1\n",
    "                    alpha = agent_ret - bench_ret\n",
    "                    print(f\"{agent_name:<12} | {stats['days']:<6} | {agent_ret:>11.2%} | {bench_ret:>11.2%} | {alpha:>11.2%}\")\n",
    "                else:\n",
    "                    print(f\"{agent_name:<12} | {0:<6} | {'N/A':>11} | {'N/A':>11} | {'0.00%':>11}\")\n",
    "            print(\"-\" * 65)\n",
    "            \n",
    "            self.plot_dashboard(res)\n",
    "            \n",
    "        return total_ret\n",
    "\n",
    "    def plot_dashboard(self, res):\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(14, 18), sharex=True, gridspec_kw={'height_ratios': [3, 2, 2, 2]})\n",
    "        plt.subplots_adjust(hspace=0.2)\n",
    "        \n",
    "        res['Bench_Equity'] = (1 + res['Benchmark']).cumprod() * self.config['INITIAL_BALANCE']\n",
    "        ax0 = axes[0]\n",
    "        ax0.plot(res.index, res['Portfolio'], label='Ensemble AI', color='black', linewidth=2)\n",
    "        ax0.plot(res.index, res['Bench_Equity'], label='Buy & Hold', color='gray', linestyle='--', alpha=0.6)\n",
    "        ax0.set_title(f\"Equity Curve: {self.config['TARGET_ASSET']}\", fontweight='bold')\n",
    "        ax0.set_ylabel(\"Portfolio Value ($)\")\n",
    "        ax0.grid(True, alpha=0.3)\n",
    "        \n",
    "        y_min, y_max = ax0.get_ylim()\n",
    "        ax0.fill_between(res.index, y_min, y_max, where=(res['Agent'] == 'trend'), color='green', alpha=0.1, label='Trend Regime')\n",
    "        ax0.fill_between(res.index, y_min, y_max, where=(res['Agent'] == 'accumulation'), color='orange', alpha=0.15, label='Accumulation')\n",
    "        ax0.fill_between(res.index, y_min, y_max, where=(res['Agent'] == 'crisis'), color='red', alpha=0.15, label='Crisis/Bear Regime')\n",
    "        ax0.legend(loc='upper left', frameon=True)\n",
    "\n",
    "        ax1 = axes[1]\n",
    "        strat_peak = res['Portfolio'].cummax()\n",
    "        strat_dd = (res['Portfolio'] - strat_peak) / strat_peak\n",
    "        ax1.fill_between(res.index, strat_dd, 0, color='red', alpha=0.3, label='Strategy Drawdown')\n",
    "        ax1.set_ylabel(\"Drawdown %\")\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        ax2 = axes[2]\n",
    "        ax2.plot(res.index, res['Trend_PnL'], label='Trend Agent', color='green', linewidth=1.5)\n",
    "        ax2.plot(res.index, res['MeanRev_PnL'], label='Accumulation', color='orange', linewidth=1.5)\n",
    "        ax2.plot(res.index, res['Crisis_PnL'], label='Crisis Agent', color='red', linewidth=1.5)\n",
    "        ax2.set_ylabel(\"Profit Contrib ($)\")\n",
    "        ax2.legend(loc='upper left')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        ax3 = axes[3]\n",
    "        colors = ['forestgreen' if r > 0 else 'firebrick' for r in res['Return']]\n",
    "        ax3.bar(res.index, res['Scale Act'], color=colors, width=1.5)\n",
    "        ax3.set_ylabel(\"Exposure\")\n",
    "        ax3.set_ylim(-0.1, self.config['MAX_LEVERAGE']*1.1)\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.show()\n",
    "class HyperparameterOptimizer:\n",
    "    def __init__(self, tickers, target):\n",
    "        self.tickers = tickers\n",
    "        self.target = target\n",
    "        \n",
    "    def optimize(self, train_start, train_end):\n",
    "        print(f\"\\n>>> STARTING HYPERPARAMETER OPTIMIZATION FOR {self.target} <<<\")\n",
    "        \n",
    "        # Grid Search Space\n",
    "        param_grid = {\n",
    "            \"WINDOW_SIZE\": [20, 60],\n",
    "            \"ADX_THRESHOLD\": [20, 25],\n",
    "            \"TARGET_VOL\": [0.20, 0.40] \n",
    "        }\n",
    "        \n",
    "        best_ret = -np.inf\n",
    "        best_config = None\n",
    "        \n",
    "        keys, values = zip(*param_grid.items())\n",
    "        combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "        \n",
    "        for i, params in enumerate(combinations):\n",
    "            print(f\"Testing Config {i+1}/{len(combinations)}: {params}\")\n",
    "            \n",
    "            # Create Config Copy\n",
    "            trial_config = DEFAULT_CONFIG.copy()\n",
    "            trial_config.update(params)\n",
    "            trial_config['TICKERS'] = self.tickers\n",
    "            trial_config['TARGET_ASSET'] = self.target\n",
    "            trial_config['TRAIN_START'] = train_start\n",
    "            trial_config['TRAIN_END'] = train_end\n",
    "            \n",
    "            # We use the last 1 year of 'Training' data as Validation for optimization\n",
    "            # In a real scenario, you'd split Train/Val properly.\n",
    "            # Here we just run a quick backtest on the TRAIN period to see fit.\n",
    "            trial_config['TEST_START'] = str(int(train_end[:4]) - 1) + train_end[4:]\n",
    "            trial_config['TEST_END'] = train_end\n",
    "            \n",
    "            # Fast Training\n",
    "            trial_config['TRAINING_STEPS'] = 10000 \n",
    "            \n",
    "            mgr = EnsembleManager(trial_config)\n",
    "            mgr.train_specialists(verbose=False)\n",
    "            ret = mgr.run_backtest(plot_results=False)\n",
    "            \n",
    "            print(f\"  -> Return: {ret:.2%}\")\n",
    "            \n",
    "            if ret > best_ret:\n",
    "                best_ret = ret\n",
    "                best_config = params\n",
    "                \n",
    "        print(f\"\\n>>> BEST PARAMETERS FOUND: {best_config} (Ret: {best_ret:.2%}) <<<\")\n",
    "        return best_config\n",
    "\n",
    "def run_system(tickers, target, start, end):\n",
    "    config = DEFAULT_CONFIG.copy()\n",
    "    config['TICKERS'] = tickers\n",
    "    config['TARGET_ASSET'] = target\n",
    "    config['TEST_START'] = start\n",
    "    config['TEST_END'] = end\n",
    "    \n",
    "    # Safety Defaults for Single Stock\n",
    "    if target != \"SPY\":\n",
    "        config['LONG_ONLY'] = True\n",
    "        config['MAX_LEVERAGE'] = 1.0\n",
    "        config['TARGET_VOL'] = 0.40\n",
    "        config['ADX_THRESHOLD'] = 25\n",
    "        config['TRAINING_STEPS'] = 50000 \n",
    "        config['USE_VOL_TARGETING'] = False \n",
    "        config['ACTION_SCALER'] = 10.0 \n",
    "\n",
    "            # if optimize:\n",
    "    # Run optimization on the period PRIOR to the test start\n",
    "    opt = HyperparameterOptimizer(tickers, target)\n",
    "    # Use 2020-2023 as optimization/validation window\n",
    "    best_params = opt.optimize(\"2016-01-01\", start) \n",
    "    config.update(best_params)\n",
    "    \n",
    "    print(\"\\n>>> INITIALIZING TRINITY V6 (ACCUMULATION MODE) <<<\")\n",
    "    mgr = EnsembleManager(config)\n",
    "    mgr.train_specialists()\n",
    "    mgr.run_backtest()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MY_TICKERS = [\"GOOG\", \"^VIX\", \"SHY\"]\n",
    "    MY_TARGET = \"GOOG\"\n",
    "    START = \"2024-01-22\"\n",
    "    END = \"2025-05-05\"\n",
    "\n",
    "    run_system(MY_TICKERS, MY_TARGET, START, END)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
